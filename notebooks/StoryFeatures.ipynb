{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string \n",
    "import scipy.io\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial import distance\n",
    "import itertools\n",
    "from sklearn import svm\n",
    "import statsmodels.api as sm # import statsmodels \n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "class Scan(object):\n",
    "    def __init__(self,activations,timestamp, step,prev_words=None,next_words=None,all_words=None,all_pos=None):\n",
    "        self.activations = activations\n",
    "        self.timestamp = timestamp\n",
    "        self.prev_words = prev_words\n",
    "        self.next_words = next_words\n",
    "        self.step = step\n",
    "        self.all_words = all_words\n",
    "        self.all_pos = all_pos\n",
    "        self.brain3d = None\n",
    "        \n",
    "def eval(dists,e_dists):\n",
    "    nn_index = np.argmin(dists,axis=1)\n",
    "    accuracy_on_test = np.mean(nn_index == np.argmax(np.eye(dists.shape[0]),axis=1))\n",
    "\n",
    "\n",
    "    b_acc = []\n",
    "    e_b_acc = []\n",
    "    for i,j in itertools.combinations(np.arange(dists.shape[0]), 2):\n",
    "        right_match = dists[i,i] + dists[j,j]\n",
    "        wrong_match = dists[i,j] + dists[j,i]\n",
    "        b_acc.append(right_match < wrong_match)\n",
    "\n",
    "        e_right_match = e_dists[i,i] + e_dists[j,j]\n",
    "        e_wrong_match = e_dists[i,j] + e_dists[j,i]\n",
    "        e_b_acc.append(e_right_match < e_wrong_match)\n",
    "\n",
    "    #print(\"binary accuracy: \", np.mean(b_acc),\" \", np.mean(e_b_acc))\n",
    "    return np.mean(b_acc),np.mean(e_b_acc),b_acc,e_b_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_features = scipy.io.loadmat('../data/story_features.mat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speach_feature_id = 1\n",
    "motion_feature_id = 2\n",
    "emotion_feature_id = 3\n",
    "verbs_feature_id = 4\n",
    "characters_feature_id = 5\n",
    "visual_wordlength_feature_id = 6\n",
    "Word_Num_feature_id = 7\n",
    "part_of_speaches_feature_id = 8\n",
    "Dependency_role_feature_id = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of_speaches = story_features['features'][0][part_of_speaches_feature_id][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Speech'], dtype='<U6'), array([[array(['speak_sticky'], dtype='<U12'),\n",
       "        array(['speak'], dtype='<U5')]], dtype=object), array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       ...,\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_features['features'][0][speach_feature_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'subject_1_block_1_pos.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-06dce271baaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mblock_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subject_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_block_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_pos.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mblock_scans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subject_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_scan_objects.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'subject_1_block_1_pos.npy'"
     ]
    }
   ],
   "source": [
    "subject_id = 1\n",
    "\n",
    "block_pos = {}\n",
    "\n",
    "for block_id in [1,2,3,4]:\n",
    "    block_pos[block_id] = np.load(\"subject_\"+str(subject_id)+\"_block_\"+str(block_id)+\"_pos.npy\")\n",
    "\n",
    "block_scans = np.load(\"subject_\"+str(subject_id)+\"_scan_objects.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'block_scans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7ce4c9e81117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_scans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_scans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_scans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_scans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'block_scans' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(block_scans.item()[1]))\n",
    "print(len(block_scans.item()[2]))\n",
    "print(len(block_scans.item()[3]))\n",
    "print(len(block_scans.item()[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_0 = np.load(\"../data/subject_\"+str(1)+\"_lstm_\"+str(0)+\"_emb_objects.npy\")\n",
    "embeddings_1 = np.load(\"../data/subject_\"+str(1)+\"_lstm_\"+str(1)+\"_emb_objects.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Scan at 0x149fed438>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_scans.item()[block_id][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detrended_block_scans = {1:[],2:[],3:[],4:[]}\n",
    "raw_block_scans = {1:[],2:[],3:[],4:[]}\n",
    "\n",
    "for block_id in [1,2,3,4]:\n",
    "        for i in np.arange(len(block_scans.item()[block_id])):\n",
    "            raw_block_scans[block_id].append(block_scans.item()[block_id][i].activations[0])\n",
    "                           \n",
    "        detrended_block_scans[block_id] = signal.detrend(raw_block_scans[block_id],type=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(train_block_ids,test_block_ids):\n",
    "    train_features = {'position':[],'pos_tag':[],'lstm_1':[],'lstm_0':[],'lstm_prev_1':[],'lstm_prev_0':[]}\n",
    "    train_brain_activations = []\n",
    "    for train_block_id in train_block_ids:\n",
    "        for i in np.arange(len(block_scans.item()[train_block_id])):\n",
    "            scan = block_scans.item()[train_block_id][i]\n",
    "            if (scan.step - 4) in embeddings_1.item()[train_block_id].keys():\n",
    "                train_features['position'].append(scan.step)\n",
    "                train_features['pos_tag'].append(np.sum(scan.all_pos,axis=0))\n",
    "                train_features['lstm_1'].append(np.mean(embeddings_1.item()[train_block_id][scan.step],axis=0))\n",
    "                train_features['lstm_0'].append(np.mean(embeddings_0.item()[train_block_id][scan.step],axis=0))\n",
    "                train_features['lstm_prev_1'].append(np.mean(embeddings_1.item()[train_block_id][scan.step-4],axis=0))\n",
    "                train_features['lstm_prev_0'].append(np.mean(embeddings_0.item()[train_block_id][scan.step-4],axis=0))\n",
    "                train_brain_activations.append(detrended_block_scans[block_id][i])\n",
    "        #print(scan.step)\n",
    "\n",
    "    test_features = {'position':[],'pos_tag':[],'lstm_1':[],'lstm_0':[],'lstm_prev_1':[],'lstm_prev_0':[]}\n",
    "    test_brain_activations = []\n",
    "    for test_block_id in test_block_ids:\n",
    "        for scan in block_scans.item()[test_block_id]:\n",
    "            if (scan.step - 4) in embeddings_1.item()[test_block_id].keys():\n",
    "                test_features['position'].append(scan.step)\n",
    "                test_features['pos_tag'].append(np.sum(scan.all_pos,axis=0))\n",
    "                test_features['lstm_1'].append(np.mean(embeddings_1.item()[test_block_id][scan.step],axis=0))\n",
    "                test_features['lstm_0'].append(np.mean(embeddings_0.item()[test_block_id][scan.step],axis=0))\n",
    "                test_features['lstm_prev_1'].append(np.mean(embeddings_1.item()[test_block_id][scan.step-4],axis=0))\n",
    "                test_features['lstm_prev_0'].append(np.mean(embeddings_0.item()[test_block_id][scan.step-4],axis=0))\n",
    "                test_brain_activations.append(scan.activations[0])\n",
    "            #print(scan.step)\n",
    "    return train_features,train_brain_activations,test_features,test_brain_activations\n",
    "\n",
    "\n",
    "def train_model(X,y):\n",
    "    #X = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n",
    "    # Note the difference in argument order\n",
    "    model = sm.OLS(y, X).fit() ## sm.OLS(output, input)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def MRR(distances):\n",
    "    prec_at_corrects = []\n",
    "    ranks = []\n",
    "    sorted_indexes = np.argsort(distances,axis=1)\n",
    "    for i in np.arange(len(distances)):\n",
    "        #print(i)\n",
    "        correct_at = np.where(sorted_indexes[i] == i)[0] + 1\n",
    "        #print(\"Reciprocal Rank\",correct_at)\n",
    "        prec_at_correct = 1.0/correct_at\n",
    "        #print(\"precision at \",correct_at,\": \",prec_at_correct)\n",
    "        prec_at_corrects.append(prec_at_correct)\n",
    "        ranks.append(correct_at)\n",
    "    \n",
    "    print(\"MRR: \",np.mean(prec_at_corrects),\" \",np.mean(ranks))\n",
    "    return np.mean(ranks), np.mean(prec_at_corrects), ranks,prec_at_corrects\n",
    "\n",
    "def test_model(model,X_t,y_t):\n",
    "    #X_t = sm.add_constant(X_t) ## let's add an intercept (beta_0) to our model\n",
    "    pred_t = model.predict(X_t)\n",
    "    \n",
    "    cosine_dists = distance.cdist(pred_t,y_t,'cosine')\n",
    "    euc_dists =  distance.cdist(pred_t,y_t,'euclidean')\n",
    "    \n",
    "    print(\"cosine dist >>\")\n",
    "    mean_ranks_c = MRR(cosine_dists)\n",
    "    \n",
    "    print(\"euc_dists dist >>\")\n",
    "    mean_ranks_e = MRR(euc_dists)\n",
    "    \n",
    "    print(\"binary accuracy >>\")\n",
    "    c_acc, e_acc, _,_ = eval(cosine_dists,euc_dists)\n",
    "    print(c_acc,e_acc)\n",
    "    \n",
    "    return c_acc, e_acc\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist >>\n",
      "MRR:  0.017749266454767033   183.0\n",
      "euc_dists dist >>\n",
      "MRR:  0.017788830331274045   182.66849315068492\n",
      "binary accuracy >>\n",
      "0.46637061568568416 0.7010236339003463\n",
      "cosine dist >>\n",
      "MRR:  0.02331461178702536   132.5\n",
      "euc_dists dist >>\n",
      "MRR:  0.023328338620199285   132.3598484848485\n",
      "binary accuracy >>\n",
      "0.4685447632215693 0.859027537734762\n",
      "cosine dist >>\n",
      "MRR:  0.0189874823175414   169.0\n",
      "euc_dists dist >>\n",
      "MRR:  0.018999607511832245   168.89317507418397\n",
      "binary accuracy >>\n",
      "0.4976685036032217 0.7276211671612265\n",
      "cosine dist >>\n",
      "MRR:  0.01957716467635644   163.0\n",
      "euc_dists dist >>\n",
      "MRR:  0.01957794248271313   162.90769230769232\n",
      "binary accuracy >>\n",
      "0.4897435897435897 0.5096486229819563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4897435897435897, 0.5096486229819563)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_block_ids = [1,2,3]\n",
    "test_block_ids = [4]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = train_features['position'] ## X usually means our input variables (or independent variables)\n",
    "y = train_brain_activations ## Y usually means our output/dependent variable\n",
    "X_t = test_features['position'] ## X usually means our input variables (or independent variables)\n",
    "y_t = test_brain_activations ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "\n",
    "train_block_ids = [1,2,4]\n",
    "test_block_ids = [3]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = train_features['position'] ## X usually means our input variables (or independent variables)\n",
    "y = train_brain_activations ## Y usually means our output/dependent variable\n",
    "X_t = test_features['position'] ## X usually means our input variables (or independent variables)\n",
    "y_t = test_brain_activations ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "\n",
    "\n",
    "train_block_ids = [1,3,4]\n",
    "test_block_ids = [2]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = train_features['position'] ## X usually means our input variables (or independent variables)\n",
    "y = train_brain_activations ## Y usually means our output/dependent variable\n",
    "X_t = test_features['position'] ## X usually means our input variables (or independent variables)\n",
    "y_t = test_brain_activations ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "\n",
    "\n",
    "train_block_ids = [2,3,4]\n",
    "test_block_ids = [1]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = train_features['position'] ## X usually means our input variables (or independent variables)\n",
    "y = train_brain_activations ## Y usually means our output/dependent variable\n",
    "X_t = test_features['position'] ## X usually means our input variables (or independent variables)\n",
    "y_t = test_brain_activations ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist >>\n",
      "MRR:  0.016317585377942964   182.3041095890411\n",
      "euc_dists dist >>\n",
      "MRR:  0.017681453576808486   182.9972602739726\n",
      "binary accuracy >>\n",
      "0.5198554869787746 0.494219479150986\n",
      "cosine dist >>\n",
      "MRR:  0.02350106051784622   132.57575757575756\n",
      "euc_dists dist >>\n",
      "MRR:  0.023629706591473253   132.49621212121212\n",
      "binary accuracy >>\n",
      "0.48476206936282984 0.5079214195183777\n",
      "cosine dist >>\n",
      "MRR:  0.018791403637603458   168.459940652819\n",
      "euc_dists dist >>\n",
      "MRR:  0.018986758140129116   168.94955489614244\n",
      "binary accuracy >>\n",
      "0.5209658047195139 0.5029143704959729\n",
      "cosine dist >>\n",
      "MRR:  0.020141206267954143   162.71384615384616\n",
      "euc_dists dist >>\n",
      "MRR:  0.01962027757690457   162.96615384615384\n",
      "binary accuracy >>\n",
      "0.5110921177587844 0.4982905982905983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5110921177587844, 0.4982905982905983)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_block_ids = [1,2,3]\n",
    "test_block_ids = [4]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = train_features['pos_tag'] ## X usually means our input variables (or independent variables)\n",
    "y = train_brain_activations ## Y usually means our output/dependent variable\n",
    "X_t = test_features['pos_tag'] ## X usually means our input variables (or independent variables)\n",
    "y_t = test_brain_activations ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "train_block_ids = [1,2,4]\n",
    "test_block_ids = [3]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = train_features['pos_tag'] ## X usually means our input variables (or independent variables)\n",
    "y = train_brain_activations ## Y usually means our output/dependent variable\n",
    "X_t = test_features['pos_tag'] ## X usually means our input variables (or independent variables)\n",
    "y_t = test_brain_activations ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "train_block_ids = [1,3,4]\n",
    "test_block_ids = [2]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = train_features['pos_tag'] ## X usually means our input variables (or independent variables)\n",
    "y = train_brain_activations ## Y usually means our output/dependent variable\n",
    "X_t = test_features['pos_tag'] ## X usually means our input variables (or independent variables)\n",
    "y_t = test_brain_activations ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "train_block_ids = [2,3,4]\n",
    "test_block_ids = [1]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = train_features['pos_tag'] ## X usually means our input variables (or independent variables)\n",
    "y = train_brain_activations ## Y usually means our output/dependent variable\n",
    "X_t = test_features['pos_tag'] ## X usually means our input variables (or independent variables)\n",
    "y_t = test_brain_activations ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist >>\n",
      "MRR:  0.031113001393879562   141.2109589041096\n",
      "euc_dists dist >>\n",
      "MRR:  0.018259458326131194   181.84657534246574\n",
      "binary accuracy >>\n",
      "0.6964323347884992 0.6950173114556676\n",
      "(1027, 2048) (1027, 37913)\n",
      "(264, 2048) (264, 37913)\n",
      "cosine dist >>\n",
      "MRR:  0.02294183217565086   130.74242424242425\n",
      "euc_dists dist >>\n",
      "MRR:  0.023170051504614507   132.4810606060606\n",
      "binary accuracy >>\n",
      "0.532204170987441 0.5296405115796751\n",
      "(954, 2048) (954, 37913)\n",
      "(337, 2048) (337, 37913)\n",
      "cosine dist >>\n",
      "MRR:  0.023565687019170306   167.47477744807122\n",
      "euc_dists dist >>\n",
      "MRR:  0.01947748384418863   168.9673590504451\n",
      "binary accuracy >>\n",
      "0.5269005228204041 0.5109509679242616\n",
      "(966, 2048) (966, 37913)\n",
      "(325, 2048) (325, 37913)\n",
      "cosine dist >>\n",
      "MRR:  0.017000900528725903   153.62153846153845\n",
      "euc_dists dist >>\n",
      "MRR:  0.019657981849459615   162.87384615384616\n",
      "binary accuracy >>\n",
      "0.6102754036087369 0.612630579297246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6102754036087369, 0.612630579297246)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_block_ids = [1,2,3]\n",
    "test_block_ids = [4]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = np.asarray(train_brain_activations) ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = np.asarray(test_brain_activations) ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "\n",
    "train_block_ids = [1,2,4]\n",
    "test_block_ids = [3]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = np.asarray(train_brain_activations) ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = np.asarray(test_brain_activations) ## Y usually means our output/dependent variable\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "print(X_t.shape,y_t.shape)\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "train_block_ids = [1,3,4]\n",
    "test_block_ids = [2]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = np.asarray(train_brain_activations) ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = np.asarray(test_brain_activations) ## Y usually means our output/dependent variable\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "print(X_t.shape,y_t.shape)\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "train_block_ids = [2,3,4]\n",
    "test_block_ids = [1]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = np.asarray(train_brain_activations) ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = np.asarray(test_brain_activations) ## Y usually means our output/dependent variable\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "print(X_t.shape,y_t.shape)\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist >>\n",
      "MRR:  0.01888116722778134   176.43013698630136\n",
      "euc_dists dist >>\n",
      "MRR:  0.014564612117998933   171.1917808219178\n",
      "binary accuracy >>\n",
      "0.5642781875658588 0.5606051482763812\n",
      "(1027, 2048) (1027, 37913)\n",
      "(264, 2048) (264, 37913)\n",
      "cosine dist >>\n",
      "MRR:  0.02715845481856617   112.67424242424242\n",
      "euc_dists dist >>\n",
      "MRR:  0.032444442325211285   117.51136363636364\n",
      "binary accuracy >>\n",
      "0.6108998732572877 0.5788397280792718\n",
      "(954, 2048) (954, 37913)\n",
      "(337, 2048) (337, 37913)\n",
      "cosine dist >>\n",
      "MRR:  0.02622329823714948   169.7507418397626\n",
      "euc_dists dist >>\n",
      "MRR:  0.01564038901589837   181.30563798219583\n",
      "binary accuracy >>\n",
      "0.4699908153172248 0.41380528472516603\n",
      "(966, 2048) (966, 37913)\n",
      "(325, 2048) (325, 37913)\n",
      "cosine dist >>\n",
      "MRR:  0.02597350361830614   152.58461538461538\n",
      "euc_dists dist >>\n",
      "MRR:  0.02628569901668747   142.9353846153846\n",
      "binary accuracy >>\n",
      "0.6239126305792972 0.5992022792022792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6239126305792972, 0.5992022792022792)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_block_ids = [1,2,3]\n",
    "test_block_ids = [4]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = np.asarray(train_brain_activations) ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = np.asarray(test_brain_activations) ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X[delay:],y[:-delay])\n",
    "test_model(model,X_t[delay:],y_t)\n",
    "\n",
    "\n",
    "train_block_ids = [1,2,4]\n",
    "test_block_ids = [3]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = np.asarray(train_brain_activations) ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = np.asarray(test_brain_activations) ## Y usually means our output/dependent variable\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "print(X_t.shape,y_t.shape)\n",
    "model = train_model(X[delay:],y)\n",
    "test_model(model,X_t[delay:],y_t)\n",
    "\n",
    "train_block_ids = [1,3,4]\n",
    "test_block_ids = [2]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = np.asarray(train_brain_activations) ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = np.asarray(test_brain_activations) ## Y usually means our output/dependent variable\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "print(X_t.shape,y_t.shape)\n",
    "model = train_model(X[delay:],y)\n",
    "test_model(model,X_t[delay:],y_t)\n",
    "\n",
    "train_block_ids = [2,3,4]\n",
    "test_block_ids = [1]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = np.asarray(train_brain_activations) ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = np.asarray(test_brain_activations) ## Y usually means our output/dependent variable\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "print(X_t.shape,y_t.shape)\n",
    "model = train_model(X[delay:],y)\n",
    "test_model(model,X_t[delay:],y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranks:  Ttest_1sampResult(statistic=array([0.27975532]), pvalue=array([0.7798237]))\n"
     ]
    }
   ],
   "source": [
    "true_mu = 361 / 2.0\n",
    "\n",
    "onesample_results = scipy.stats.ttest_1samp(ranks, true_mu)\n",
    "print(\"ranks: \", onesample_results)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
