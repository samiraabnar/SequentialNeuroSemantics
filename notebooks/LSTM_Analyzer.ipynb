{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string \n",
    "import scipy.io\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial import distance\n",
    "import itertools\n",
    "from sklearn import svm\n",
    "import statsmodels.api as sm # import statsmodels \n",
    "from scipy import signal\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "\n",
    "class Scan(object):\n",
    "    def __init__(self,activations,timestamp, step,prev_words=None,next_words=None,all_words=None,all_pos=None):\n",
    "        self.activations = activations\n",
    "        self.timestamp = timestamp\n",
    "        self.prev_words = prev_words\n",
    "        self.next_words = next_words\n",
    "        self.step = step\n",
    "        self.all_words = all_words\n",
    "        self.all_pos = all_pos\n",
    "        self.brain3d = None\n",
    "        \n",
    "def eval(dists,e_dists):\n",
    "    nn_index = np.argmin(dists,axis=1)\n",
    "    accuracy_on_test = np.mean(nn_index == np.argmax(np.eye(dists.shape[0]),axis=1))\n",
    "\n",
    "\n",
    "    b_acc = []\n",
    "    e_b_acc = []\n",
    "    for i,j in itertools.combinations(np.arange(dists.shape[0]), 2):\n",
    "        right_match = dists[i,i] + dists[j,j]\n",
    "        wrong_match = dists[i,j] + dists[j,i]\n",
    "        b_acc.append(right_match < wrong_match)\n",
    "\n",
    "        e_right_match = e_dists[i,i] + e_dists[j,j]\n",
    "        e_wrong_match = e_dists[i,j] + e_dists[j,i]\n",
    "        e_b_acc.append(e_right_match < e_wrong_match)\n",
    "\n",
    "    #print(\"binary accuracy: \", np.mean(b_acc),\" \", np.mean(e_b_acc))\n",
    "    return np.mean(b_acc),np.mean(e_b_acc),b_acc,e_b_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_0 = np.load(\"../data/subject_\"+str(1)+\"_lstm_\"+str(0)+\"_emb_objects.npy\")\n",
    "embeddings_1 = np.load(\"../data/subject_\"+str(1)+\"_lstm_\"+str(1)+\"_emb_objects.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_0.item()[1][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'subject_1_block_1_pos.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4b40958da30f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mblock_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subject_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_block_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_pos.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mblock_scans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subject_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_scan_objects.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'subject_1_block_1_pos.npy'"
     ]
    }
   ],
   "source": [
    "subject_id = 1\n",
    "\n",
    "block_pos = {}\n",
    "\n",
    "for block_id in [1,2,3,4]:\n",
    "    block_pos[block_id] = np.load(\"subject_\"+str(subject_id)+\"_block_\"+str(block_id)+\"_pos.npy\")\n",
    "\n",
    "block_scans = np.load(\"subject_\"+str(subject_id)+\"_scan_objects.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'block_scans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-da272df5ae9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_scans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mraw_block_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_scans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'block_scans' is not defined"
     ]
    }
   ],
   "source": [
    "detrended_block_scans = {1:[],2:[],3:[],4:[]}\n",
    "raw_block_scans = {1:[],2:[],3:[],4:[]}\n",
    "\n",
    "for block_id in [1,2,3,4]:\n",
    "        for i in np.arange(len(block_scans.item()[block_id])):\n",
    "            raw_block_scans[block_id].append(block_scans.item()[block_id][i].activations[0])\n",
    "                           \n",
    "        detrended_block_scans[block_id] = signal.detrend(raw_block_scans[block_id],type=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_LSTM_Diagnostic_data(train_block_ids,test_block_ids):\n",
    "    train_features = {'position':[],'pos_tag':[],'lstm_1':[],'lstm_0':[],'lstm_prev_1':[],'lstm_prev_0':[]}\n",
    "    train_brain_activations = []\n",
    "    for train_block_id in train_block_ids:\n",
    "        for i in np.arange(len(block_scans.item()[train_block_id])):\n",
    "            scan = block_scans.item()[train_block_id][i]\n",
    "            if (scan.step - 4) in embeddings_1.item()[train_block_id].keys():\n",
    "                train_features['position'].append(scan.step)\n",
    "                train_features['pos_tag'].append(np.sum(scan.all_pos,axis=0))\n",
    "                train_features['lstm_1'].append(np.mean(embeddings_1.item()[train_block_id][scan.step],axis=0))\n",
    "                train_features['lstm_0'].append(np.mean(embeddings_0.item()[train_block_id][scan.step],axis=0))\n",
    "                train_features['lstm_prev_1'].append(np.mean(embeddings_1.item()[train_block_id][scan.step-4],axis=0))\n",
    "                train_features['lstm_prev_0'].append(np.mean(embeddings_0.item()[train_block_id][scan.step-4],axis=0))\n",
    "                train_brain_activations.append(detrended_block_scans[block_id][i])\n",
    "        #print(scan.step)\n",
    "\n",
    "    test_features = {'position':[],'pos_tag':[],'lstm_1':[],'lstm_0':[],'lstm_prev_1':[],'lstm_prev_0':[]}\n",
    "    test_brain_activations = []\n",
    "    for test_block_id in test_block_ids:\n",
    "        for scan in block_scans.item()[test_block_id]:\n",
    "            if (scan.step - 4) in embeddings_1.item()[test_block_id].keys():\n",
    "                test_features['position'].append(scan.step)\n",
    "                test_features['pos_tag'].append(np.sum(scan.all_pos,axis=0))\n",
    "                test_features['lstm_1'].append(np.mean(embeddings_1.item()[test_block_id][scan.step],axis=0))\n",
    "                test_features['lstm_0'].append(np.mean(embeddings_0.item()[test_block_id][scan.step],axis=0))\n",
    "                test_features['lstm_prev_1'].append(np.mean(embeddings_1.item()[test_block_id][scan.step-4],axis=0))\n",
    "                test_features['lstm_prev_0'].append(np.mean(embeddings_0.item()[test_block_id][scan.step-4],axis=0))\n",
    "                test_brain_activations.append(scan.activations[0])\n",
    "            #print(scan.step)\n",
    "    return train_features,train_brain_activations,test_features,test_brain_activations\n",
    "\n",
    "\n",
    "def train_model(X,y):\n",
    "    #X = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n",
    "    # Note the difference in argument order\n",
    "    model = sm.OLS(y, X).fit() ## sm.OLS(output, input)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def MRR(distances):\n",
    "    prec_at_corrects = []\n",
    "    ranks = []\n",
    "    sorted_indexes = np.argsort(distances,axis=1)\n",
    "    for i in np.arange(len(distances)):\n",
    "        #print(i)\n",
    "        correct_at = np.where(sorted_indexes[i] == i)[0] + 1\n",
    "        #print(\"Reciprocal Rank\",correct_at)\n",
    "        prec_at_correct = 1.0/correct_at\n",
    "        #print(\"precision at \",correct_at,\": \",prec_at_correct)\n",
    "        prec_at_corrects.append(prec_at_correct)\n",
    "        ranks.append(correct_at)\n",
    "    \n",
    "    print(\"MRR: \",np.mean(prec_at_corrects),\" \",np.mean(ranks))\n",
    "    return np.mean(ranks), np.mean(prec_at_corrects), ranks,prec_at_corrects\n",
    "\n",
    "def test_model(model,X_t,y_t):\n",
    "    #X_t = sm.add_constant(X_t) ## let's add an intercept (beta_0) to our model\n",
    "    pred_t = model.predict(X_t)\n",
    "    \n",
    "    if len(pred_t.shape) == 1:\n",
    "        pred_t = np.reshape(pred_t,(len(pred_t),1))\n",
    "        y_t = np.reshape(y_t,(len(y_t),1))\n",
    "\n",
    "    cosine_dists = distance.cdist(pred_t,y_t,'cosine')\n",
    "    euc_dists =  distance.cdist(pred_t,y_t,'euclidean')\n",
    "    \n",
    "    print(\"cosine dist >>\")\n",
    "    mean_ranks_c = MRR(cosine_dists)\n",
    "    \n",
    "    print(\"euc_dists dist >>\")\n",
    "    mean_ranks_e = MRR(euc_dists)\n",
    "    \n",
    "    print(\"binary accuracy >>\")\n",
    "    c_acc, e_acc, _,_ = eval(cosine_dists,euc_dists)\n",
    "    print(c_acc,e_acc)\n",
    "    \n",
    "    return c_acc, e_acc\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist >>\n",
      "MRR:  0.017749266454767033   183.0\n",
      "euc_dists dist >>\n",
      "MRR:  0.017800852927025462   182.44931506849315\n",
      "binary accuracy >>\n",
      "0.0 0.010913743790456119\n",
      "cosine dist >>\n",
      "MRR:  0.023314611787025357   132.5\n",
      "euc_dists dist >>\n",
      "MRR:  0.031855638771678504   96.61742424242425\n",
      "binary accuracy >>\n",
      "0.0 0.4815646963935937\n",
      "cosine dist >>\n",
      "MRR:  0.0189874823175414   169.0\n",
      "euc_dists dist >>\n",
      "MRR:  0.020238638095098377   172.95548961424333\n",
      "binary accuracy >>\n",
      "0.0 0.2905009184682775\n",
      "cosine dist >>\n",
      "MRR:  0.01957716467635644   163.0\n",
      "euc_dists dist >>\n",
      "MRR:  0.01985333379303804   160.9046153846154\n",
      "binary accuracy >>\n",
      "0.0 0.043076923076923075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.043076923076923075)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_block_ids = [1,2,3]\n",
    "test_block_ids = [4]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_LSTM_Diagnostic_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = train_features['position'] ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = test_features['position'] ## Y usually means our output/dependent variable\n",
    "\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "\n",
    "train_block_ids = [1,2,4]\n",
    "test_block_ids = [3]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_LSTM_Diagnostic_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = train_features['position'] ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = test_features['position'] ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "\n",
    "\n",
    "train_block_ids = [1,3,4]\n",
    "test_block_ids = [2]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_LSTM_Diagnostic_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = train_features['position'] ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = test_features['position'] ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "\n",
    "\n",
    "train_block_ids = [2,3,4]\n",
    "test_block_ids = [1]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_LSTM_Diagnostic_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = train_features['position'] ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = test_features['position'] ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist >>\n",
      "MRR:  0.4403195210638416   11.547945205479452\n",
      "euc_dists dist >>\n",
      "MRR:  0.43552268886366513   17.616438356164384\n",
      "binary accuracy >>\n",
      "0.993602288122836 0.9934517537257264\n",
      "cosine dist >>\n",
      "MRR:  0.4810815942966132   8.693181818181818\n",
      "euc_dists dist >>\n",
      "MRR:  0.47322600983211116   10.43939393939394\n",
      "binary accuracy >>\n",
      "0.9927987095287476 0.9932307869570227\n",
      "cosine dist >>\n",
      "MRR:  0.47775870864261805   13.492581602373887\n",
      "euc_dists dist >>\n",
      "MRR:  0.467783871392112   15.216617210682493\n",
      "binary accuracy >>\n",
      "0.9922813338985446 0.9925639395223965\n",
      "cosine dist >>\n",
      "MRR:  0.47880161968712137   11.458461538461538\n",
      "euc_dists dist >>\n",
      "MRR:  0.48979442120770394   13.612307692307692\n",
      "binary accuracy >>\n",
      "0.9932003798670466 0.9935422602089269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9932003798670466, 0.9935422602089269)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_block_ids = [1,2,3]\n",
    "test_block_ids = [4]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_LSTM_Diagnostic_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = train_features['pos_tag'] ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = test_features['pos_tag'] ## Y usually means our output/dependent variable\n",
    "\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "\n",
    "train_block_ids = [1,2,4]\n",
    "test_block_ids = [3]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_LSTM_Diagnostic_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = train_features['pos_tag'] ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = test_features['pos_tag'] ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "\n",
    "\n",
    "train_block_ids = [1,3,4]\n",
    "test_block_ids = [2]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_LSTM_Diagnostic_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = train_features['pos_tag'] ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = test_features['pos_tag'] ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n",
    "\n",
    "\n",
    "train_block_ids = [2,3,4]\n",
    "test_block_ids = [1]\n",
    "train_features,train_brain_activations,test_features,test_brain_activations = \\\n",
    "                                                prepare_LSTM_Diagnostic_data(train_block_ids,test_block_ids)\n",
    "\n",
    "\n",
    "X = np.concatenate([train_features['lstm_0'],train_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y = train_features['pos_tag'] ## Y usually means our output/dependent variable\n",
    "X_t = np.concatenate([test_features['lstm_0'],test_features['lstm_1']],axis=1) ## X usually means our input variables (or independent variables)\n",
    "y_t = test_features['pos_tag'] ## Y usually means our output/dependent variable\n",
    "\n",
    "model = train_model(X,y)\n",
    "test_model(model,X_t,y_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
