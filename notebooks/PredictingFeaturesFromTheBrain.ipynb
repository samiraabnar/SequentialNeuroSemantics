{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string \n",
    "import scipy.io\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial import distance\n",
    "import itertools\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import *\n",
    "\n",
    "\n",
    "\n",
    "class Scan(object):\n",
    "    def __init__(self,activations,timestamp, step,prev_words=None,next_words=None,all_words=None,all_pos=None,all_speak_features=None,current_translated_words=None):\n",
    "        self.activations = activations\n",
    "        self.timestamp = timestamp\n",
    "        self.prev_words = prev_words\n",
    "        self.next_words = next_words\n",
    "        self.step = step\n",
    "        self.all_words = all_words\n",
    "        self.current_translated_words = current_translated_words\n",
    "        self.all_pos = all_pos\n",
    "        self.all_speak_features = all_speak_features\n",
    "        self.brain3d = None\n",
    "        \n",
    "        \n",
    "        \n",
    "subject_id = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_brain_features(block_features, block_scans, block_ids):\n",
    "    brains = []\n",
    "    features = []\n",
    "    for block_id in block_ids:\n",
    "        for scan in block_scans.item()[block_id]:\n",
    "            block_step = scan.step  - block_scans.item()[block_id][0].step\n",
    "            brains.append(scan.activations[0])\n",
    "\n",
    "            related_features = []\n",
    "            i = 0\n",
    "            while i<4 and (block_step + i) < len(block_features[block_id]):\n",
    "                related_features.append(block_features[block_id][block_step + i])\n",
    "                i += 1\n",
    "\n",
    "            features.append(max(related_features))  \n",
    "    \n",
    "    print(len(features),len(brains))\n",
    "    brains = np.asarray(brains)\n",
    "    brains = (brains - np.min(brains,axis=0))/(np.max(brains,axis=0) - np.min(brains,axis=0) + 0.000001)\n",
    "    return brains, features     \n",
    "\n",
    "\n",
    "def evaluate_fold_brain_features(feature_model, block_scans,test_blocks,train_blocks):\n",
    "    brains_train, features_train = fold_brain_features(feature_model,block_scans,block_ids=train_blocks)\n",
    "    brains_test, features_test = fold_brain_features(feature_model,block_scans,block_ids=test_blocks)\n",
    "\n",
    "\n",
    "    clf = SVC(kernel='linear',class_weight='balanced', C=0.001)\n",
    "    clf.fit(brains_train, features_train)\n",
    "\n",
    "    prediction_train = clf.predict(brains_train)\n",
    "    prediction_test = clf.predict(brains_test)\n",
    "\n",
    "    train_accuracy = np.mean(features_train == prediction_train)\n",
    "    test_accuracy = np.mean(features_test == prediction_test)\n",
    "\n",
    "    print(\"train accuracy: \",train_accuracy, \" test accuracy: \",test_accuracy)\n",
    "    cnf_matrix = confusion_matrix(features_test, prediction_test)\n",
    "    print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_brain_vectors = np.load(\"../processed_data/512reducted_brain_scans.npy\")\n",
    "not_reduced_brain_vectors = np.load(\"../processed_data/reducted_brain_scans.npy\")\n",
    "\n",
    "reduced_brain_vectors_words = np.load(\"../processed_data/reducted_words.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reduced_brain_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reduced_brain_vectors_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_features = scipy.io.loadmat('../data/story_features.mat') \n",
    "subject_file = scipy.io.loadmat('../data/'+'subject_'+str(subject_id)+'.mat') \n",
    "part_of_speaches_feature_id = 8\n",
    "speach_feature_id = 1\n",
    "part_of_speaches = story_features['features'][0][part_of_speaches_feature_id][1][0]\n",
    "part_of_speaches_features = story_features['features'][0][part_of_speaches_feature_id][2]\n",
    "speaches = story_features['features'][0][speach_feature_id][1][0]\n",
    "speach_features = story_features['features'][0][speach_feature_id][2]\n",
    "\n",
    "\n",
    "speach_feature_id = 1\n",
    "motion_feature_id = 2\n",
    "emotion_feature_id = 3\n",
    "verbs_feature_id = 4\n",
    "characters_feature_id = 5\n",
    "visual_wordlength_feature_id = 6\n",
    "Word_Num_feature_id = 7\n",
    "part_of_speaches_feature_id = 8\n",
    "Dependency_role_feature_id = 9\n",
    "\n",
    "word_index = 0\n",
    "time_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: array([680], dtype=uint16), 2: array([1384], dtype=uint16), 3: array([1942], dtype=uint16), 4: array([2702], dtype=uint16)}\n",
      "{1: array([339]), 2: array([691]), 3: array([970]), 4: array([1350])}\n"
     ]
    }
   ],
   "source": [
    "actual_words = []\n",
    "word_times = []\n",
    "word_pos = []\n",
    "speach_states = []\n",
    "for i in np.arange(subject_file['words'].shape[1]):\n",
    "    actual_words.append(subject_file['words'][0][i][word_index][0][0][0].strip().replace(\"@\",\"\"))\n",
    "    word_times.append(subject_file['words'][0][i][time_index][0][0])\n",
    "    word_pos.append(part_of_speaches_features[i])\n",
    "    speach_states.append(speach_features[i])\n",
    "    \n",
    "    \n",
    "blocks = subject_file['time'][:,1]\n",
    "scan_times = subject_file['time'][:,0]\n",
    "\n",
    "block_ends = {}\n",
    "block_ends_indexes = {}\n",
    "\n",
    "\n",
    "for block_id in np.arange(1,5):\n",
    "    block_ends_indexes[block_id] = np.where(scan_times == np.max(scan_times[np.where(blocks == block_id )]))[0]\n",
    "    block_ends[block_id] = scan_times[block_ends_indexes[block_id]]+2\n",
    "\n",
    "\n",
    "print(block_ends)\n",
    "print(block_ends_indexes)\n",
    "\n",
    "block_texts = {1:[],2:[],3:[],4:[]}\n",
    "block_pos = {1:[],2:[],3:[],4:[]}\n",
    "block_speach_state = {1:[],2:[],3:[],4:[]}\n",
    "block_steps = {1:[],2:[],3:[],4:[]}\n",
    "character_feature = {1:[],2:[],3:[],4:[]}\n",
    "block_id = 1\n",
    "for index in np.arange(len(actual_words)):\n",
    "    if word_times[index] > block_ends[block_id]:\n",
    "        block_id += 1\n",
    "    block_texts[block_id].append(str(actual_words[index].encode(\"ascii\",'ignore').decode()))\n",
    "    block_pos[block_id].append(word_pos[index])\n",
    "    block_speach_state[block_id].append(speach_states[index][0])\n",
    "    block_steps[block_id].append(index)\n",
    "    character_feature[block_id].append(story_features['features'][0][characters_feature_id][2][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "end_of_sentence_indexes = {1:[],2:[],3:[],4:[]}\n",
    "start_of_sentence_indexes = {1:[],2:[],3:[],4:[]}\n",
    "qout_indexes = {1:[],2:[],3:[],4:[]}\n",
    "inside_qout_indexes = {1:[],2:[],3:[],4:[]}\n",
    "\n",
    "for block_id in [1,2,3,4]:\n",
    "    start_of_sentence_indexes[block_id].append(0)\n",
    "    inside_qout = False\n",
    "    for i in np.arange(len(block_texts[block_id])):\n",
    "        \n",
    "        already_in = False   \n",
    "        if \"\\\"\" in block_texts[block_id][i]:\n",
    "            qout_indexes[block_id].append(i)\n",
    "            \n",
    "            checked = False\n",
    "            if block_texts[block_id][i].strip().startswith(\"\\\"\"):\n",
    "                if inside_qout is False :\n",
    "                    if already_in == False:\n",
    "                        inside_qout_indexes[block_id].append(i)\n",
    "                        already_in = True\n",
    "                inside_qout = not inside_qout\n",
    "                checked = True\n",
    "                \n",
    "            if block_texts[block_id][i].strip().endswith(\"\\\"\"):\n",
    "                if inside_qout is True :\n",
    "                    if already_in == False:\n",
    "                        inside_qout_indexes[block_id].append(i) \n",
    "                        already_in = True\n",
    "                inside_qout = not inside_qout\n",
    "                checked = True\n",
    "                \n",
    "            if checked == False:\n",
    "                print(block_texts[block_id][i])\n",
    "                \n",
    "        if inside_qout:\n",
    "            if already_in == False:\n",
    "                inside_qout_indexes[block_id].append(i)\n",
    "        #end/start of sentence\n",
    "        truth_table = [punc in block_texts[block_id][i] for punc in [\"!\",\".\",\"?\",\":\"]]\n",
    "        if True in truth_table:\n",
    "            end_of_sentence_indexes[block_id].append(i)\n",
    "            if i+1 < len(block_texts[block_id]):\n",
    "                start_of_sentence_indexes[block_id].append(i+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_qout_feature = {1:[],2:[],3:[],4:[]}\n",
    "start_sentence_feature = {1:[],2:[],3:[],4:[]}\n",
    "end_sentence_feature = {1:[],2:[],3:[],4:[]}\n",
    "for block_id in [1,2,3,4]:\n",
    "    inside_qout_feature[block_id] = np.zeros((len(block_texts[block_id])))\n",
    "    inside_qout_feature[block_id][inside_qout_indexes[block_id]] = 1\n",
    "    \n",
    "    start_sentence_feature[block_id] = np.zeros((len(block_texts[block_id])))\n",
    "    start_sentence_feature[block_id][start_of_sentence_indexes[block_id]] = 1\n",
    "\n",
    "    end_sentence_feature[block_id] = np.zeros((len(block_texts[block_id])))\n",
    "    end_sentence_feature[block_id][end_of_sentence_indexes[block_id]] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_feature = character_feature\n",
    "brain_mapped_features = []\n",
    "for block_id in [1,2,3,4]:\n",
    "    for j in np.arange(0,len(block_feature[block_id]),4):\n",
    "        i = 0\n",
    "        related_features = []\n",
    "        while i < 4 and (i+j) < len(block_feature[block_id]):\n",
    "            if max(block_feature[block_id][i+j]) == 0:\n",
    "                related_features.append(0)\n",
    "            else:\n",
    "                related_features.append(1+ np.argmax(block_feature[block_id][i+j]))\n",
    "            i += 1\n",
    "        \n",
    "        brain_mapped_features.append(np.max(related_features))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1295,)\n",
      "(1295, 512)\n",
      "(1295, 37913)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(brain_mapped_features).shape)\n",
    "print(np.asarray(reduced_brain_vectors).shape)\n",
    "print(np.asarray(not_reduced_brain_vectors).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.485\n",
      "[[94  4 28  2  0  0  3  1  2  2]\n",
      " [13  0  3  0  0  0  0  0  0  0]\n",
      " [ 8  1  2  2  0  1  1  0  0  0]\n",
      " [ 2  1  1  1  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [10  0  3  0  0  1  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]]\n",
      "MRR:  0.2827262581168831\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=1,class_weight='balanced',probability=True)\n",
    "clf.fit(reduced_brain_vectors[200+1:], brain_mapped_features[200:len(brain_mapped_features)-1])\n",
    "\n",
    "prediction_test = clf.predict(reduced_brain_vectors[1:200+1])\n",
    "probability_prediction_test = clf.predict_proba(reduced_brain_vectors[1:200+1])\n",
    "\n",
    "\n",
    "train_accuracy = np.mean(brain_mapped_features[:200] == prediction_test)\n",
    "\n",
    "print(\"accuracy: \",train_accuracy)\n",
    "cnf_matrix = confusion_matrix(brain_mapped_features[:200], prediction_test)\n",
    "print(cnf_matrix)\n",
    "\n",
    "result = []\n",
    "for i in np.arange(len(brain_mapped_features[:200])):\n",
    "    if brain_mapped_features[:200][i] > 0:\n",
    "        j = np.where (np.argsort(probability_prediction_test[i]) == np.asarray(brain_mapped_features[:200][i]))\n",
    "        result.append(1/(11 - j[0][0]))\n",
    "    \n",
    "print(\"MRR: \",np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.51\n",
      "[[98  7  1 19  6  0  1  2  2  0]\n",
      " [10  1  0  1  3  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 9  0  0  2  2  0  1  0  1  0]\n",
      " [ 4  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [11  0  0  2  0  0  1  1  0  0]\n",
      " [ 6  1  0  2  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]]\n",
      "MRR:  0.2753782242063492\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=1,class_weight='balanced',probability=True)\n",
    "clf.fit(reduced_brain_vectors[200+2:], brain_mapped_features[200:len(brain_mapped_features)-2])\n",
    "\n",
    "prediction_test = clf.predict(reduced_brain_vectors[2:200+2])\n",
    "probability_prediction_test = clf.predict_proba(reduced_brain_vectors[2:200+2])\n",
    "\n",
    "\n",
    "train_accuracy = np.mean(brain_mapped_features[:200] == prediction_test)\n",
    "\n",
    "print(\"accuracy: \",train_accuracy)\n",
    "cnf_matrix = confusion_matrix(brain_mapped_features[:200], prediction_test)\n",
    "print(cnf_matrix)\n",
    "\n",
    "result = []\n",
    "for i in np.arange(len(brain_mapped_features[:200])):\n",
    "    if brain_mapped_features[:200][i] > 0:\n",
    "        j = np.where (np.argsort(probability_prediction_test[i]) == np.asarray(brain_mapped_features[:200][i]))\n",
    "        result.append(1/(11 - j[0][0]))\n",
    "    \n",
    "print(\"MRR: \",np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.515\n",
      "[[97  2 25  1  0  2  3  2  2  2]\n",
      " [10  1  4  1  0  0  0  0  0  0]\n",
      " [ 9  0  5  0  0  0  0  0  1  0]\n",
      " [ 0  0  4  0  0  0  1  1  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0]\n",
      " [11  0  2  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  1  0  0  0  0  1  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]]\n",
      "MRR:  0.2878229843073593\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=1,class_weight='balanced',probability=True)\n",
    "clf.fit(reduced_brain_vectors[200+3:], brain_mapped_features[200:len(brain_mapped_features)-3])\n",
    "\n",
    "prediction_test = clf.predict(reduced_brain_vectors[3:200+3])\n",
    "probability_prediction_test = clf.predict_proba(reduced_brain_vectors[3:200+3])\n",
    "\n",
    "\n",
    "train_accuracy = np.mean(brain_mapped_features[:200] == prediction_test)\n",
    "\n",
    "print(\"accuracy: \",train_accuracy)\n",
    "cnf_matrix = confusion_matrix(brain_mapped_features[:200], prediction_test)\n",
    "print(cnf_matrix)\n",
    "\n",
    "result = []\n",
    "for i in np.arange(len(brain_mapped_features[:200])):\n",
    "    if brain_mapped_features[:200][i] > 0:\n",
    "        j = np.where (np.argsort(probability_prediction_test[i]) == np.asarray(brain_mapped_features[:200][i]))\n",
    "        result.append(1/(11 - j[0][0]))\n",
    "    \n",
    "print(\"MRR: \",np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.46\n",
      "[[87  2 24  7  1  1  8  3  3]\n",
      " [12  1  2  0  0  0  1  0  0]\n",
      " [10  0  4  0  0  1  0  0  0]\n",
      " [ 2  1  3  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0]\n",
      " [11  0  3  1  0  0  0  0  0]\n",
      " [ 8  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n",
      "MRR:  0.2843073593073593\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=1,class_weight='balanced',probability=True)\n",
    "clf.fit(reduced_brain_vectors[200+4:], brain_mapped_features[200:len(brain_mapped_features)-4])\n",
    "\n",
    "prediction_test = clf.predict(reduced_brain_vectors[4:200+4])\n",
    "probability_prediction_test = clf.predict_proba(reduced_brain_vectors[4:200+4])\n",
    "\n",
    "\n",
    "train_accuracy = np.mean(brain_mapped_features[:200] == prediction_test)\n",
    "\n",
    "print(\"accuracy: \",train_accuracy)\n",
    "cnf_matrix = confusion_matrix(brain_mapped_features[:200], prediction_test)\n",
    "print(cnf_matrix)\n",
    "\n",
    "result = []\n",
    "for i in np.arange(len(brain_mapped_features[:200])):\n",
    "    if brain_mapped_features[:200][i] > 0:\n",
    "        j = np.where (np.argsort(probability_prediction_test[i]) == np.asarray(brain_mapped_features[:200][i]))\n",
    "        result.append(1/(11 - j[0][0]))\n",
    "    \n",
    "print(\"MRR: \",np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_mapped_features[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.68\n",
      "[[133   0   3   0   0   0   0   0]\n",
      " [ 16   0   0   0   0   0   0   0]\n",
      " [ 12   0   3   0   0   0   0   0]\n",
      " [  6   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0]\n",
      " [ 15   0   0   0   0   0   0   0]\n",
      " [ 10   0   0   0   0   0   0   0]]\n",
      "MRR:  0.2567775974025974\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=1,class_weight='balanced',probability=True)\n",
    "clf.fit(not_reduced_brain_vectors[200:], brain_mapped_features[200:])\n",
    "\n",
    "prediction_test = clf.predict(not_reduced_brain_vectors[:200])\n",
    "probability_prediction_test = clf.predict_proba(not_reduced_brain_vectors[:200])\n",
    "\n",
    "\n",
    "train_accuracy = np.mean(brain_mapped_features[:200] == prediction_test)\n",
    "\n",
    "print(\"accuracy: \",train_accuracy)\n",
    "cnf_matrix = confusion_matrix(brain_mapped_features[:200], prediction_test)\n",
    "print(cnf_matrix)\n",
    "\n",
    "result = []\n",
    "for i in np.arange(len(brain_mapped_features[:200])):\n",
    "    if brain_mapped_features[:200][i] > 0:\n",
    "        j = np.where (np.argsort(probability_prediction_test[i]) == np.asarray(brain_mapped_features[:200][i]))\n",
    "        result.append(1/(11 - j[0][0]))\n",
    "    \n",
    "print(\"MRR: \",np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
