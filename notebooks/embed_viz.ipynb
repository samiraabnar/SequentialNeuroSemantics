{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "\n",
    "LOG_DIR =os.path.join(os.getcwd(),'fmrisample')\n",
    "NAME_TO_VISUALISE_VARIABLE = \"fmri_embedding\"\n",
    "\n",
    "\n",
    "path_for_mnist_sprites =  os.path.join(LOG_DIR,'fmris.png')\n",
    "path_for_mnist_metadata =  os.path.join(LOG_DIR,'metadata.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Scan(object):\n",
    "    def __init__(self, activations, timestamp, step, word=None, prev_word=None, next_word=None):\n",
    "        self.activations = activations\n",
    "        self.timestamp = timestamp\n",
    "        self.word = word\n",
    "        self.prev_word = prev_word\n",
    "        self.next_word = next_word\n",
    "        self.step = step\n",
    "\n",
    "\n",
    "        \n",
    "def read_and_prepare_data():\n",
    "    scan_objects = np.load(\"../data/subject_1_scan_objects.npy\")\n",
    "    embeddings = np.load(\"../data/lstm_emb_objects.npy\")\n",
    "    # print(len(scan_objects.item().get(1)))\n",
    "    # print(embeddings.item().get(1))\n",
    "    block_id = 1\n",
    "    brain_scans = []\n",
    "    brain_scan_steps = []\n",
    "    current_word = []\n",
    "    lstm_embeddings = []\n",
    "    words = []\n",
    "    for scan_obj in scan_objects.item().get(block_id):\n",
    "        # print(scan_obj.step, scan_obj.word, scan_obj.timestamp)\n",
    "        brain_scans.append(scan_obj.activations[0])\n",
    "        brain_scan_steps.append(scan_obj.step)\n",
    "        current_word.append(scan_obj.word)\n",
    "        lstm_embeddings.append(embeddings.item().get(block_id)[scan_obj.step])\n",
    "        if scan_obj.prev_word == None:\n",
    "            scan_obj.prev_word =\"\"\n",
    "        if scan_obj.next_word == None:\n",
    "            scan_obj.next_word =\"\"\n",
    "        words.append(scan_obj.prev_word+\"_\"+scan_obj.word+\"_\"+scan_obj.next_word)\n",
    "\n",
    "    brain_scans = np.asarray(brain_scans)\n",
    "    brain_scan_steps = np.asarray(brain_scan_steps)\n",
    "    current_word = np.asarray(current_word)\n",
    "    lstm_embeddings = np.asarray(lstm_embeddings)\n",
    "    words = np.asarray(words)\n",
    "\n",
    "    min_voxel_value = np.min(brain_scans)\n",
    "    max_voxel_value = np.max(brain_scans)\n",
    "    print(\"brain scans min max: %f %f\" % (min_voxel_value, max_voxel_value))\n",
    "    normalized_brain_scans = (brain_scans - min_voxel_value) / (max_voxel_value - min_voxel_value)\n",
    "    nmin_voxel_value = np.min(normalized_brain_scans)\n",
    "    nmax_voxel_value = np.max(normalized_brain_scans)\n",
    "    print(\"normalized brain scans min max: %f %f\" % (nmin_voxel_value, nmax_voxel_value))\n",
    "    print(len(normalized_brain_scans))\n",
    "    return lstm_embeddings, normalized_brain_scans, words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brain scans min max: -91.000000 1068.000000\n",
      "normalized brain scans min max: 0.000000 1.000000\n",
      "326\n"
     ]
    }
   ],
   "source": [
    "lstm_embeddings, normalized_brain_scans, words = read_and_prepare_data()\n",
    "\n",
    "#lstm_embeddings, normalized_brain_scans, words = lstm_embeddings[:100], normalized_brain_scans[:100], words[:100]\n",
    "embedding_var = tf.Variable(lstm_embeddings, name=NAME_TO_VISUALISE_VARIABLE)\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "\n",
    "# Specify where you find the metadata\n",
    "embedding.metadata_path = path_for_mnist_metadata #'metadata.tsv'\n",
    "\n",
    "# Specify where you find the sprite (we will create this later)\n",
    "#embedding.sprite.image_path = path_for_mnist_sprites #'mnistdigits.png'\n",
    "#embedding.sprite.single_image_dim.extend([28,28])\n",
    "\n",
    "# Say that you want to visualise the embeddings\n",
    "projector.visualize_embeddings(summary_writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/samiraabnar/Codes/SequentialNeuroSemantics/data/fmrisample/model.ckpt-1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sprite_image(images):\n",
    "    \"\"\"Returns a sprite image consisting of images passed as argument. Images should be count x width x height\"\"\"\n",
    "    if isinstance(images, list):\n",
    "        images = np.array(images)\n",
    "    img_h = images.shape[1]\n",
    "    img_w = images.shape[2]\n",
    "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    \n",
    "    \n",
    "    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
    "    \n",
    "    for i in range(n_plots):\n",
    "        for j in range(n_plots):\n",
    "            this_filter = i * n_plots + j\n",
    "            if this_filter < images.shape[0]:\n",
    "                this_img = images[this_filter]\n",
    "                spriteimage[i * img_h:(i + 1) * img_h,\n",
    "                  j * img_w:(j + 1) * img_w] = this_img\n",
    "    \n",
    "    return spriteimage\n",
    "\n",
    "def vector_to_matrix_mnist(mnist_digits):\n",
    "    \"\"\"Reshapes normal mnist digit (batch,28*28) to matrix (batch,28,28)\"\"\"\n",
    "    return np.reshape(mnist_digits,(-1,28,28))\n",
    "\n",
    "def invert_grayscale(mnist_digits):\n",
    "    \"\"\" Makes black white, and white black \"\"\"\n",
    "    return 1-mnist_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to_visualise = batch_xs\n",
    "#to_visualise = vector_to_matrix_mnist(to_visualise)\n",
    "#to_visualise = invert_grayscale(to_visualise)\n",
    "\n",
    "#sprite_image = create_sprite_image(to_visualise)\n",
    "\n",
    "#plt.imsave(path_for_mnist_sprites,sprite_image,cmap='gray')\n",
    "#plt.imshow(sprite_image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path_for_mnist_metadata,'w') as f:\n",
    "    f.write(\"Index\\tLabel\\tifTarget\\n\")\n",
    "    for index,label in enumerate(words):\n",
    "        f.write(\"%d\\t%s\\t%d\\n\" % (index,label,if_target[index-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
